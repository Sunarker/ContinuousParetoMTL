{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd68bc462d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source code for ICML submission #640 \"Efficient Continuous Pareto Exploration in Multi-Task Learning\"\n",
    "# This script generates Figure 4 in the paper.\n",
    "\n",
    "import codecs\n",
    "import gzip\n",
    "import os\n",
    "import urllib\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import scipy.optimize\n",
    "\n",
    "from common import *\n",
    "\n",
    "# Fix the random seed.\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST training images and labels into root_folder.\n",
    "# Returns (images, labels).\n",
    "# images is of dimension 60k x h x w, labels is of dimension 60k.\n",
    "def download_mnist_training(root_folder):\n",
    "    # Helper function.\n",
    "    def get_int(b):\n",
    "        return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "    # Download data.\n",
    "    image_url = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "    label_url = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "    for url in (image_url, label_url):\n",
    "        data = urllib.request.urlopen(url)\n",
    "        name = url.rpartition('/')[2]\n",
    "        file_path = os.path.join(root_folder, name)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(data.read())\n",
    "        with open(file_path.replace('.gz', ''), 'wb') as out_f, gzip.GzipFile(file_path) as zip_f:\n",
    "            out_f.write(zip_f.read())\n",
    "        os.remove(file_path)\n",
    "\n",
    "    # Extract images.\n",
    "    with open(os.path.join(root_folder, 'train-images-idx3-ubyte'), 'rb') as f:\n",
    "        data = f.read()\n",
    "        # Check the magic number and metadata.\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        assert length == 60000\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        assert num_rows == num_cols == 28\n",
    "        # Read images.\n",
    "        image_data = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "        images = image_data.reshape(length, num_rows, num_cols)\n",
    "\n",
    "    # Extract labels.\n",
    "    with open(os.path.join(root_folder, 'train-labels-idx1-ubyte'), 'rb') as f:\n",
    "        data = f.read()\n",
    "        # Check the magic number and metadata.\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        assert length == 60000\n",
    "        label_data = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        labels = label_data.ravel()\n",
    "    return images, labels\n",
    "\n",
    "root_folder = 'MultiMNISTSubset'\n",
    "mnist_images, mnist_labels = download_mnist_training(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MNIST.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "choice = np.random.choice(mnist_labels.size, 16, replace=False)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax = fig.add_subplot(4, 4, i * 4 + j + 1)\n",
    "        ax.matshow(mnist_images[choice[i * 4 + j]])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('label: {}'.format(mnist_labels[choice[i * 4 + j]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate MultiMNIST.\n",
    "# Returns (images, left_label, right_label).\n",
    "# images is of size (number, h, w), left_label and right_label are of size (number,)\n",
    "def generate_multi_mnist(number):\n",
    "    multi_images = []\n",
    "    left_labels = []\n",
    "    right_labels = []\n",
    "    mnist_size = mnist_labels.size\n",
    "    left = np.random.permutation(mnist_size)[:number]\n",
    "    right = np.random.permutation(mnist_size)[:number]\n",
    "    for l, r in zip(left, right):\n",
    "        left_labels.append(mnist_labels[l])\n",
    "        right_labels.append(mnist_labels[r])\n",
    "\n",
    "        left_image = mnist_images[l]\n",
    "        right_image = mnist_images[r]\n",
    "        # Randomly shift left and right images.\n",
    "        if np.random.rand() < 0.5:\n",
    "            shift_left = np.random.randint(3)\n",
    "            shift_right = np.random.randint(4)\n",
    "        else:\n",
    "            shift_left = np.random.randint(4)\n",
    "            shift_right = np.random.randint(3)\n",
    "        \n",
    "        new_image = np.zeros((36, 36))\n",
    "        new_image[shift_left:shift_left + 28, shift_left:shift_left + 28] += left_image\n",
    "        new_image[8 - shift_right:36 - shift_right, 8 - shift_right:36 - shift_right] += right_image\n",
    "\n",
    "        # Post-processing.\n",
    "        new_image = np.clip(new_image, 0, 255).astype(mnist_images[0].dtype)\n",
    "        # Downsample the image to 14 x 14.\n",
    "        new_image = np.array(Image.fromarray(new_image).resize((14, 14), resample=Image.NEAREST))\n",
    "        multi_images.append(new_image)\n",
    "    return multi_images, left_labels, right_labels\n",
    "\n",
    "subset_size = 2048\n",
    "multi_images, left_labels, right_labels = generate_multi_mnist(subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MultiMNIST.\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "choice = np.random.choice(subset_size, 16, replace=False)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax = fig.add_subplot(4, 4, i * 4 + j + 1)\n",
    "        idx = choice[i * 4 + j]\n",
    "        ax.matshow(multi_images[idx])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('label: {}, {}'.format(left_labels[idx], right_labels[idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network.\n",
    "class MiniLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniLeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, (5, 5), stride=2)\n",
    "        self.fc1 = nn.Linear(40, 20)\n",
    "        self.fc3_1 = nn.Linear(20, 10)\n",
    "        self.fc3_2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = [self.fc3_1(x), self.fc3_2(x)]\n",
    "        return x\n",
    "\n",
    "network = MiniLeNet()\n",
    "x0 = ndarray(parameters_to_vector(network.parameters()).clone().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss.\n",
    "# Transform images to torch tensors and normalize them.\n",
    "# For MNIST, mean = 0.1307, std = 0.3081\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# Dim of multi_images_torch: #images x #channels x height x width.\n",
    "multi_images_torch = torch.stack([transform(Image.fromarray(img)) for img in multi_images], dim=0)\n",
    "\n",
    "# Label shape: (#images,)\n",
    "left_labels_torch = torch.from_numpy(ndarray(left_labels)).long()\n",
    "right_labels_torch = torch.from_numpy(ndarray(right_labels)).long()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 0.0, w2: 1.0\n",
      "results:       fun: array(0.63615155)\n",
      " hess_inv: <1500x1500 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 3.91322561e-03,  8.73468816e-05,  1.56715978e-04, ...,\n",
      "       -1.37265006e-05, -1.94658598e-04, -5.56853483e-05])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 5961\n",
      "      nit: 5736\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.5433707 , -0.14053733,  0.45805089, ..., -1.20540721,\n",
      "        1.15076842,  0.29510445])\n",
      "loss and grad: (array(9.06728935), array(0.63615155))\n",
      "w1: 0.25, w2: 0.75\n",
      "results:       fun: array(1.08264875)\n",
      " hess_inv: <1500x1500 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-3.93918878e-03, -2.39904039e-03,  7.45779776e-04, ...,\n",
      "        9.76262418e-05, -1.06018611e-04,  1.24812770e-04])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 2693\n",
      "      nit: 2623\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.55156134,  0.44546869, -0.29037922, ..., -2.24437082,\n",
      "        2.64036137,  0.03306795])\n",
      "loss and grad: (array(1.09944236), array(1.07705092))\n",
      "w1: 0.5, w2: 0.5\n",
      "results:       fun: array(0.96194923)\n",
      " hess_inv: <1500x1500 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-5.48856333e-04,  1.14510115e-03,  9.78753902e-04, ...,\n",
      "       -2.20030142e-06, -1.04810006e-05,  7.52629057e-05])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 2996\n",
      "      nit: 2946\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.14869588,  0.20830665,  0.15045695, ..., -2.98488319,\n",
      "        2.16587032,  0.45084841])\n",
      "loss and grad: (array(0.50803912), array(1.41585934))\n",
      "w1: 0.75, w2: 0.25\n",
      "results:       fun: array(0.70850801)\n",
      " hess_inv: <1500x1500 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 2.59302324e-04,  5.67705836e-04,  2.66431388e-03, ...,\n",
      "       -6.13014927e-05, -1.05714553e-05, -1.07649848e-05])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 4691\n",
      "      nit: 4481\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.79867814,  0.40249803,  0.31130326, ..., -1.37635963,\n",
      "        0.65079462, -0.43930804])\n",
      "loss and grad: (array(0.22456285), array(2.16034365))\n"
     ]
    }
   ],
   "source": [
    "# Generate empirical Pareto front.\n",
    "# Depending on your choice of num_trials, this process can take a while.\n",
    "# For 101 trials, this cell took 45 minutes to finish (PyTorch CPU). We actually used GPU in our experiments, which is\n",
    "# way faster than CPUs. However, we intend to keep this example simple to set up so we didn't include our GPU version\n",
    "# in this script.\n",
    "# We have also attached the training results in this code repository for num_trials = 101. If you don't plan to use\n",
    "# a new num_trials, executing this cell will be super fast.\n",
    "num_trials = 5\n",
    "def get_loss(x):\n",
    "    x_torch = torch.as_tensor(x, dtype=torch.float)\n",
    "    vector_to_parameters(x_torch, network.parameters())\n",
    "    logits = network(multi_images_torch)\n",
    "    loss_left, loss_right = loss_function(logits[0], left_labels_torch), loss_function(logits[1], right_labels_torch)\n",
    "    loss_left = loss_left.double().clone().detach().cpu().numpy()\n",
    "    loss_right = loss_right.double().clone().detach().cpu().numpy()\n",
    "    return loss_left, loss_right\n",
    "\n",
    "for w1 in np.linspace(0, 1, num_trials):\n",
    "    w2 = 1 - w1\n",
    "\n",
    "    def loss_and_grad(x):\n",
    "        # Convert x to tensor.\n",
    "        x_torch = torch.as_tensor(x, dtype=torch.float)\n",
    "\n",
    "        # Compute loss.\n",
    "        vector_to_parameters(x_torch, network.parameters())\n",
    "        logits = network(multi_images_torch)\n",
    "        loss_left, loss_right = loss_function(logits[0], left_labels_torch), loss_function(logits[1], right_labels_torch)\n",
    "        loss_torch = w1 * loss_left + w2 * loss_right\n",
    "        loss = loss_torch.double().clone().detach().cpu().numpy()\n",
    "\n",
    "        # Compute gradients.\n",
    "        grad = 0\n",
    "        for loss_node, w in [(loss_left, w1), (loss_right, w2)]:\n",
    "            grad_node = list(torch.autograd.grad(loss_node, network.parameters(), retain_graph=True, allow_unused=True))\n",
    "            for i, (grad_module, param) in enumerate(zip(grad_node, network.parameters())):\n",
    "                if grad_module is None:\n",
    "                    grad_node[i] = torch.zeros_like(param)\n",
    "            grad_vec = parameters_to_vector(grad_node)\n",
    "            grad += grad_vec.double().clone().detach().numpy() * w\n",
    "        #print('w1: {}, w2: {}, loss: {}, grad: {}'.format(w1, w2, loss, np.linalg.norm(grad)))\n",
    "        return loss, grad\n",
    "\n",
    "    data_file = os.path.join(root_folder, '{:.2f}_{:.2f}.bin'.format(w1, w2))\n",
    "    #if not os.path.exists(data_file):\n",
    "    result = scipy.optimize.minimize(loss_and_grad, x0, method='L-BFGS-B', jac=True, bounds=None)\n",
    "    x = result.x\n",
    "    print('w1: {}, w2: {}'.format(w1, w2))\n",
    "    print('results:', result)\n",
    "    print('loss and grad:', get_loss(x))\n",
    "    pickle.dump(x, open(data_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the empirical Pareto front.\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Helper function.\n",
    "# Input: numpy array of size 1500.\n",
    "# Output: two scalars representing the left loss and right loss.\n",
    "def get_loss(x):\n",
    "    x_torch = torch.as_tensor(x, dtype=torch.float)\n",
    "    vector_to_parameters(x_torch, network.parameters())\n",
    "    logits = network(multi_images_torch)\n",
    "    loss_left, loss_right = loss_function(logits[0], left_labels_torch), loss_function(logits[1], right_labels_torch)\n",
    "    loss_left = loss_left.double().clone().detach().cpu().numpy()\n",
    "    loss_right = loss_right.double().clone().detach().cpu().numpy()\n",
    "    return loss_left, loss_right\n",
    "\n",
    "pareto_front = []\n",
    "for w1 in np.linspace(0, 1, num_trials):\n",
    "    w2 = 1 - w1\n",
    "    data_file = os.path.join(root_folder, '{:.2f}_{:.2f}.bin'.format(w1, w2))\n",
    "    x = pickle.load(open(data_file, 'rb'))\n",
    "    pareto_front.append(get_loss(x))\n",
    "\n",
    "pareto_front = ndarray(pareto_front)\n",
    "ax.scatter(pareto_front[:, 0], pareto_front[:, 1], c='k')\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69.43066406,  1.13781726],\n",
       "       [ 2.6763103 ,  1.11721623],\n",
       "       [ 1.95574057,  1.10417998],\n",
       "       [ 1.82927787,  1.09711087],\n",
       "       [ 1.82162964,  1.10605049],\n",
       "       [ 1.73173606,  1.09060371],\n",
       "       [ 1.70210242,  1.10607243],\n",
       "       [ 1.71688175,  1.10694396],\n",
       "       [ 1.68528295,  1.11643124],\n",
       "       [ 1.66520798,  1.11060786],\n",
       "       [ 1.64345551,  1.13728034],\n",
       "       [ 1.60336745,  1.13769543],\n",
       "       [ 1.57139778,  1.20075488],\n",
       "       [ 1.45916653,  1.19604611],\n",
       "       [ 1.43582714,  1.22470582],\n",
       "       [ 1.35479331,  1.16825151],\n",
       "       [ 1.32347548,  1.24417531],\n",
       "       [ 1.29005885,  1.2070626 ],\n",
       "       [ 1.30735242,  1.21402895],\n",
       "       [ 1.24484754,  1.22244608],\n",
       "       [ 1.28228545,  1.2275275 ],\n",
       "       [ 1.28953004,  1.26608634],\n",
       "       [ 1.41393459,  1.24997652],\n",
       "       [ 1.42970979,  1.34190285],\n",
       "       [ 1.71911907,  1.439116  ],\n",
       "       [ 1.42637861,  1.36297512],\n",
       "       [ 1.36112976,  1.25696182],\n",
       "       [ 1.43816376,  1.49806118],\n",
       "       [ 1.91014469,  1.7523216 ],\n",
       "       [ 1.4240092 ,  1.40767729],\n",
       "       [ 1.6152494 ,  1.61415255],\n",
       "       [ 2.11673737,  1.68645096],\n",
       "       [ 1.68838263,  1.77139032],\n",
       "       [ 2.00453091,  1.75859523],\n",
       "       [ 1.93879807,  1.7820828 ],\n",
       "       [ 1.82099593,  1.76822686],\n",
       "       [ 2.07580519,  2.16247439],\n",
       "       [ 2.04430914,  1.86596835],\n",
       "       [ 2.05203199,  1.84640193],\n",
       "       [ 2.24351835,  2.26543164],\n",
       "       [ 2.17464256,  2.21555161],\n",
       "       [ 2.29646444,  2.29695368],\n",
       "       [ 2.29645181,  2.29693294],\n",
       "       [ 1.9020741 ,  2.23467422],\n",
       "       [ 1.24147892,  2.18865418],\n",
       "       [ 1.66322243,  2.26918554],\n",
       "       [ 1.04180598,  2.26157403],\n",
       "       [ 2.2947185 ,  2.29082441],\n",
       "       [ 2.26918697,  2.27407169],\n",
       "       [ 1.62584579,  2.27027512],\n",
       "       [ 1.57274008,  2.22812891],\n",
       "       [ 1.99978006,  2.2391808 ],\n",
       "       [ 2.04791594,  2.22213292],\n",
       "       [ 1.94180012,  2.18415499],\n",
       "       [ 1.05903006,  2.23191214],\n",
       "       [ 1.68419909,  2.24136639],\n",
       "       [ 1.99981856,  2.24470115],\n",
       "       [ 2.00073457,  2.24557805],\n",
       "       [ 2.29645848,  2.29694033],\n",
       "       [ 1.69906974,  2.27919531],\n",
       "       [ 1.73285961,  2.29283524],\n",
       "       [ 1.00903916,  2.26609635],\n",
       "       [ 0.83439803,  2.22226548],\n",
       "       [ 1.65616429,  2.28654623],\n",
       "       [ 1.99235427,  2.29079723],\n",
       "       [ 1.67036784,  2.29095817],\n",
       "       [ 2.27710032,  2.29305434],\n",
       "       [ 2.29645085,  2.29692054],\n",
       "       [ 2.28643084,  2.29257059],\n",
       "       [ 2.29644895,  2.29693413],\n",
       "       [ 2.27623725,  2.29181147],\n",
       "       [ 2.27723765,  2.28931546],\n",
       "       [ 2.27174973,  2.28887057],\n",
       "       [ 2.29646373,  2.29696441],\n",
       "       [ 2.28932476,  2.29379249],\n",
       "       [ 1.48988569,  2.28025079],\n",
       "       [ 2.29645491,  2.29693437],\n",
       "       [ 2.27298617,  2.28927088],\n",
       "       [ 2.00491238,  2.28794169],\n",
       "       [ 1.7053467 ,  2.28857851],\n",
       "       [ 2.29294229,  2.29564285],\n",
       "       [ 2.0905478 ,  2.29089189],\n",
       "       [ 1.71651042,  2.29301357],\n",
       "       [ 1.34616339,  2.27107477],\n",
       "       [ 1.60795116,  2.28774571],\n",
       "       [ 1.57402349,  2.29344296],\n",
       "       [ 0.86414301,  2.26599789],\n",
       "       [ 1.33587086,  2.29025722],\n",
       "       [ 1.54471445,  2.28487229],\n",
       "       [ 1.21278119,  2.27961874],\n",
       "       [ 1.27333128,  2.2734344 ],\n",
       "       [ 1.44695878,  2.28822017],\n",
       "       [ 1.51785183,  2.29348969],\n",
       "       [ 1.40514553,  2.29653263],\n",
       "       [ 1.13231242,  2.28553176],\n",
       "       [ 0.81086397,  2.28291488],\n",
       "       [ 1.2253089 ,  2.28310418],\n",
       "       [ 1.01707685,  2.28706527],\n",
       "       [ 0.98279268,  2.27657461],\n",
       "       [ 0.85632259,  2.30585456],\n",
       "       [ 0.98940462, 62.6342659 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto_front"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
